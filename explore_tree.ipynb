{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-23 18:31:35,035: (73) DEBUG Fast version of gensim.models.doc2vec is being used\n",
      "2018-01-23 18:31:35,038: (20) INFO 'pattern' package not found; tag filters are not available for English\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s: (%(lineno)s) %(levelname)s %(message)s\")\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (18, 6)\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "from semeval_fca import find_paths_to_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "## Sparse embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-23 18:31:35,273: (9) INFO (1000, 164398)\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-86839dde7e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/makrai/repo/fca_hypernymy/data/1A.vocab'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msym_mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tool/python/venv3/lib/python3.4/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \"\"\"\n\u001b[0;32m--> 302\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tool/python/venv3/lib/python3.4/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    367\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dimension mismatch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mul_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;31m# If it's a list or whatever, treat it like a matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tool/python/venv3/lib/python3.4/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36m_mul_sparse_matrix\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    538\u001b[0m                                     maxval=nnz)\n\u001b[1;32m    539\u001b[0m         \u001b[0mindptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0midx_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnnz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_dir ='/mnt/store/hlt/Work/hypernym18-SemEval/'\n",
    "\n",
    "# Reading mx\n",
    "mx_filen = os.path.join(\n",
    "    data_dir, \n",
    "    'mx/1A_UMBC_tokenized.txt_100_sg.vec.gz_True_1000_0.2_unit_True_vocabulary_filtered.alph.reduced2') \n",
    "with open(mx_filen, 'rb') as f:\n",
    "    mx = pickle.load(f, encoding='latin1') \n",
    "logging.info(mx.shape)\n",
    "vocab = [line.strip() for line in open('/home/makrai/repo/fca_hypernymy/data/1A.vocab')]\n",
    "\n",
    "sym_mx = mx.T.dot(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('{}.w2v'.format(mx_filen), mode='w') as out_file:\n",
    "    for w, row in zip(vocab, mx.todense()):\n",
    "        out_file.write('{}\\t{}\\n'.format(w, ' '.join('{}'.format(coord) for coord in row.tolist()[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_mx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.argsort(sym_mx, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors[vocab.index('cowpox')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed.index2word = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed.syn0 = mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'dog' in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'/mnt/store/hlt/Work/hypernym18-SemEval/mx/1A_UMBC_tokenized.txt_100_sg.vec.gz_True_1000_0.2_unit_True_vocabulary_filtered.alph.reduced'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freq cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_dir = '/mnt/permanent/Language/English/Data/SemEval/2018/Hypernym/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_filen = os.path.join(task_dir, 'frequency_lists/1A_english_frequencylist.txt')\n",
    "freqs = defaultdict(lambda: 1)\n",
    "freqs.update({l.split(\"\\t\")[0]: int(l.split(\"\\t\")[1]) for l in open(freq_filen)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golds = [t for l in open(os.path.join(task_dir, 'main_data/training/gold/1A.english.training.gold.txt'))\n",
    "         for t in l.strip().split('\\t')]\n",
    "plt.hist([0 if g not in freqs else np.log10(freqs[g]) for g in golds])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([l.strip() for l in open(os.path.join(task_dir, 'main_data/vocabulary/1A.english.vocabulary.txt'))])\n",
    "\n",
    "words_left = lambda x, threshold, vocabulary: [word for word, f in x.items() if f > threshold and word in vocabulary]\n",
    "\n",
    "\n",
    "\n",
    "for threshold in 25 * np.arange(5):\n",
    "    s = set(words_left(freqs, threshold, vocab))\n",
    "    print('{}\\t{:.2%}\\t{}/{}\\t{:.2%}\\t{}/{}'.format(threshold, \n",
    "                                            len(s)/len(vocab), \n",
    "                                            len(s), len(vocab), \n",
    "                                             len([g for g in golds if g in s])/len(golds),\n",
    "                                            len([g for g in golds if g in s]), len(golds)\n",
    "                                           ))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.inf('')\n",
    "J = json.load(open(os.path.join(\n",
    "    data_dir,\n",
    "    'concept_tree/1A_UMBC_tokenized.txt_100_sg.vec.gz_True_1000_0.2_unit_True_vocabulary_filtered_reduced.cxt.json'))\n",
    "logging.inf('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mind3 visszaadott lista olyan hosszú lesz, mint ahányféleképp el lehetett jutni a gyökérből egy olyan csúcsig, amiben megtalálható volt a lekérdezett szó\n",
    "\n",
    "* a `path` ezeknek az utaknak a visszafejtését tartalmazza, \n",
    "* a `nodes` magát azt a csúcsot, ahol az i. út véget ért\n",
    "* a `depths` pedig azt hogy a gyökértől milyen mélyen helyezkedik el ez a bizonyos csúcs\n",
    "\n",
    "\n",
    "elvileg redundáns is, tehát a `paths` i. elemében egy olyan listát kell találj, ami egy gyökérben végződő utat kódol, és a `depths` i. értékéül épp ennek az útnak a hosszát kell lásd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_based_print(words, max_len=6):\n",
    "    items = sorted([(w, freqs[w]) for w in words], key=lambda it: it[1], reverse=True)\n",
    "    ans = '  '.join('{} {:.2}'.format(\n",
    "        w,#re.sub(' ', '_', w),\n",
    "        log10(f),) for w, f in items[:max_len])\n",
    "    len_ = len(words)\n",
    "    if len_ > max_len:\n",
    "        ans += '... ({})'.format(len_)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_path(query_word):#='dhow'\n",
    "    \"\"\"\n",
    "    Prints pathes from the deepest (most specific) occurrence to the full set.\n",
    "    \"\"\"\n",
    "    paths, nodes, depths = find_paths_to_object(J, query_word)\n",
    "    logging.info(len(paths))\n",
    "    max_depth = -1\n",
    "    for path, node, depth in reversed(list(zip(paths, nodes, depths))):\n",
    "        if depth < max_depth:\n",
    "            break\n",
    "        else:\n",
    "            max_depth = depth\n",
    "        print(\n",
    "            #'dhow' in node, # == True \n",
    "            freq_based_print(node), depth)\n",
    "        for node2 in path[:-1]:\n",
    "            if len(node2['own_objects']):\n",
    "                #print('{}\\t{}\\t{}'.format(my_print(node2['attributes']), node2['Node'], my_print(node2['own_objects'])))\n",
    "                print('{}'.format(freq_based_print(node2['own_objects'])))#, max_len=11)))\n",
    "            else:\n",
    "                atts = 'attributes'\n",
    "                print('{}: {} (no own object)'.format(atts, node2[atts]))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_path('cowpox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freq of hyper vs hypo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_d = {\n",
    "    (True, True): 'k',\n",
    "    (True, False): 'b',\n",
    "    (False, True): 'c',\n",
    "    (False, False): 'r',\n",
    "}\n",
    "\n",
    "\n",
    "query_freqs, gold_freqs, colors, sizes = [], [], [], []\n",
    "with open(os.path.join(task_dir, 'main_data/training/train.1A.by_freq')) as infile:\n",
    "    for line in infile:\n",
    "        query, freq, ent_conc, golds = line.strip().split('\\t', maxsplit=3)\n",
    "        for gold in golds.split('\\t'):\n",
    "            query_freqs.append(freqs[query])\n",
    "            gold_freqs.append(freqs[gold])\n",
    "            colors.append(color_d[' ' in query, ' ' in gold])\n",
    "            sizes.append(10 if ' ' in query else 5)\n",
    "          \n",
    "            \n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.scatter(query_freqs, gold_freqs, c=colors, s=sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lattice exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag = nx.read_gpickle('/mnt/permanent/home/makrai/project/hypernym18-SemEval/top500words.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dag.number_of_nodes(), dag.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dag.nodes['node175']['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
