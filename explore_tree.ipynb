{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import logging\n",
    "logging.basicConfig(level=logging.DEBUG, format=\"%(asctime)s: (%(lineno)s) %(levelname)s %(message)s\")\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (18, 6)\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "from semeval_fca import find_paths_to_object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline\n",
    "\n",
    "## Dense embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir ='/mnt/store/hlt/Work/hypernym18-SemEval/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-23 19:29:09,375: (204) INFO loading projection weights from /mnt/store/hlt/Work/hypernym18-SemEval/mx/1A_UMBC_tokenized.txt_100_sg.vec\n"
     ]
    }
   ],
   "source": [
    "embed = KeyedVectors.load_word2vec_format(os.path.join(data_dir, 'mx/1A_UMBC_tokenized.txt_100_sg.vec'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed.sav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparse embedding, TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-23 19:15:29,752: (9) INFO (1000, 164398)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading mx\n",
    "mx_filen = os.path.join(\n",
    "    data_dir, \n",
    "    'mx/1A_UMBC_tokenized.txt_100_sg.vec.gz_True_1000_0.2_unit_True_vocabulary_filtered.alph.reduced2') \n",
    "with open(mx_filen, 'rb') as f:\n",
    "    mx = pickle.load(f, encoding='latin1') \n",
    "logging.info(mx.shape)\n",
    "vocab = [line.strip() for line in open('/home/makrai/repo/fca_hypernymy/data/1A.vocab')]\n",
    "mx = mx.T\n",
    "mx = mx[:10000] # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 0 is out of bounds for array of dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-4fbf9e52430b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tool/python/venv3/lib/python3.5/site-packages/numpy/linalg/linalg.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2196\u001b[0m             \u001b[0;31m# special case for speedup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2197\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2198\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2199\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 0 is out of bounds for array of dimension 0"
     ]
    }
   ],
   "source": [
    "numpy.linalg.norm(mx, axis=0, ord=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-01-23 19:00:50,882: (9) INFO (1000, 164398)\n"
     ]
    }
   ],
   "source": [
    "logging.info('Computing symilarities...')\n",
    "sym_mx = mx.T.dot(mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1349919574154201"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sym_mx.getnnz()/sym_mx.shape[0]/sym_mx.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b19f44d0a98a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msym_mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msym_mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/tool/python/venv3/lib/python3.5/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_deduped_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mastype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tool/python/venv3/lib/python3.5/site-packages/scipy/sparse/data.py\u001b[0m in \u001b[0;36m_deduped_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_deduped_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sum_duplicates'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tool/python/venv3/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msum_duplicates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_canonical_format\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0mM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tool/python/venv3/lib/python3.5/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36msort_indices\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1060\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m             _sparsetools.csr_sort_indices(len(self.indptr) - 1, self.indptr,\n\u001b[0;32m-> 1062\u001b[0;31m                                           self.indices, self.data)\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_sorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logging.info('Computing\n",
    "sym_mx = sym_mx.astype('float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = sym_mx[vocab.index('cowpox')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20932"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.argsort(sym_mx.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbors = np.argsort(sym_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sym_mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighbors[vocab.index('cowpox')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed.index2word = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed.syn0 = mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed['dog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'dog' in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'/mnt/store/hlt/Work/hypernym18-SemEval/mx/1A_UMBC_tokenized.txt_100_sg.vec.gz_True_1000_0.2_unit_True_vocabulary_filtered.alph.reduced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('{}.w2v'.format(mx_filen), mode='w') as out_file:\n",
    "    for w, row in zip(vocab, mx.todense()):\n",
    "        out_file.write('{}\\t{}\\n'.format(w, ' '.join('{}'.format(coord) for coord in row.tolist()[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freq cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "task_dir = '/mnt/permanent/Language/English/Data/SemEval/2018/Hypernym/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "freq_filen = os.path.join(task_dir, 'frequency_lists/1A_english_frequencylist.txt')\n",
    "freqs = defaultdict(lambda: 1)\n",
    "freqs.update({l.split(\"\\t\")[0]: int(l.split(\"\\t\")[1]) for l in open(freq_filen)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "golds = [t for l in open(os.path.join(task_dir, 'main_data/training/gold/1A.english.training.gold.txt'))\n",
    "         for t in l.strip().split('\\t')]\n",
    "plt.hist([0 if g not in freqs else np.log10(freqs[g]) for g in golds])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set([l.strip() for l in open(os.path.join(task_dir, 'main_data/vocabulary/1A.english.vocabulary.txt'))])\n",
    "\n",
    "words_left = lambda x, threshold, vocabulary: [word for word, f in x.items() if f > threshold and word in vocabulary]\n",
    "\n",
    "\n",
    "\n",
    "for threshold in 25 * np.arange(5):\n",
    "    s = set(words_left(freqs, threshold, vocab))\n",
    "    print('{}\\t{:.2%}\\t{}/{}\\t{:.2%}\\t{}/{}'.format(threshold, \n",
    "                                            len(s)/len(vocab), \n",
    "                                            len(s), len(vocab), \n",
    "                                             len([g for g in golds if g in s])/len(golds),\n",
    "                                            len([g for g in golds if g in s]), len(golds)\n",
    "                                           ))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tree exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logging.inf('')\n",
    "J = json.load(open(os.path.join(\n",
    "    data_dir,\n",
    "    'concept_tree/1A_UMBC_tokenized.txt_100_sg.vec.gz_True_1000_0.2_unit_True_vocabulary_filtered_reduced.cxt.json'))\n",
    "logging.inf('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mind3 visszaadott lista olyan hosszú lesz, mint ahányféleképp el lehetett jutni a gyökérből egy olyan csúcsig, amiben megtalálható volt a lekérdezett szó\n",
    "\n",
    "* a `path` ezeknek az utaknak a visszafejtését tartalmazza, \n",
    "* a `nodes` magát azt a csúcsot, ahol az i. út véget ért\n",
    "* a `depths` pedig azt hogy a gyökértől milyen mélyen helyezkedik el ez a bizonyos csúcs\n",
    "\n",
    "\n",
    "elvileg redundáns is, tehát a `paths` i. elemében egy olyan listát kell találj, ami egy gyökérben végződő utat kódol, és a `depths` i. értékéül épp ennek az útnak a hosszát kell lásd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def freq_based_print(words, max_len=6):\n",
    "    items = sorted([(w, freqs[w]) for w in words], key=lambda it: it[1], reverse=True)\n",
    "    ans = '  '.join('{} {:.2}'.format(\n",
    "        w,#re.sub(' ', '_', w),\n",
    "        log10(f),) for w, f in items[:max_len])\n",
    "    len_ = len(words)\n",
    "    if len_ > max_len:\n",
    "        ans += '... ({})'.format(len_)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_path(query_word):#='dhow'\n",
    "    \"\"\"\n",
    "    Prints pathes from the deepest (most specific) occurrence to the full set.\n",
    "    \"\"\"\n",
    "    paths, nodes, depths = find_paths_to_object(J, query_word)\n",
    "    logging.info(len(paths))\n",
    "    max_depth = -1\n",
    "    for path, node, depth in reversed(list(zip(paths, nodes, depths))):\n",
    "        if depth < max_depth:\n",
    "            break\n",
    "        else:\n",
    "            max_depth = depth\n",
    "        print(\n",
    "            #'dhow' in node, # == True \n",
    "            freq_based_print(node), depth)\n",
    "        for node2 in path[:-1]:\n",
    "            if len(node2['own_objects']):\n",
    "                #print('{}\\t{}\\t{}'.format(my_print(node2['attributes']), node2['Node'], my_print(node2['own_objects'])))\n",
    "                print('{}'.format(freq_based_print(node2['own_objects'])))#, max_len=11)))\n",
    "            else:\n",
    "                atts = 'attributes'\n",
    "                print('{}: {} (no own object)'.format(atts, node2[atts]))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print_path('cowpox')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freq of hyper vs hypo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_d = {\n",
    "    (True, True): 'k',\n",
    "    (True, False): 'b',\n",
    "    (False, True): 'c',\n",
    "    (False, False): 'r',\n",
    "}\n",
    "\n",
    "\n",
    "query_freqs, gold_freqs, colors, sizes = [], [], [], []\n",
    "with open(os.path.join(task_dir, 'main_data/training/train.1A.by_freq')) as infile:\n",
    "    for line in infile:\n",
    "        query, freq, ent_conc, golds = line.strip().split('\\t', maxsplit=3)\n",
    "        for gold in golds.split('\\t'):\n",
    "            query_freqs.append(freqs[query])\n",
    "            gold_freqs.append(freqs[gold])\n",
    "            colors.append(color_d[' ' in query, ' ' in gold])\n",
    "            sizes.append(10 if ' ' in query else 5)\n",
    "          \n",
    "            \n",
    "plt.xscale('log')\n",
    "plt.yscale('log')\n",
    "plt.scatter(query_freqs, gold_freqs, c=colors, s=sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depths[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lattice exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dag = nx.read_gpickle('/mnt/permanent/home/makrai/project/hypernym18-SemEval/top500words.gpickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dag.number_of_nodes(), dag.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(dag.nodes['node175']['label'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
